{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 機器學習理論與實作 I\n",
    "\n",
    "### 講師：杜岳華"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/Deep_Learning_Icons_R5.png\" width=\"90%\">\n",
    "\n",
    "> [picture source](https://blogs.nvidia.com.tw/2016/07/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is AI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> ***The intelligence demonstrated by machines.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> ***The science and engineering of making intelligent machines.*** - John McCarthy, 1956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 邏輯\n",
    "* 知識表示\n",
    "* 機率論、統計與決策理論\n",
    "* 賽局理論\n",
    "* 電腦視覺\n",
    "* 自然語言處理\n",
    "* 規劃與最佳化\n",
    "* 學習與適應"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is intelligence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 會觀察、了解，並且對於人事物做出反應\n",
    "* 可以找到最佳的方法\n",
    "* 能夠推論及規劃\n",
    "* 能夠學習並調適"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The beginning of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/movie_014407_114559.jpg\" width=\"40%\">\n",
    "\n",
    "> [picture source](http://cdn.worldscreen.com.tw/uploadfile/201410/movie_014407_114559.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Alan Turing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"pics/Alan_Turing_Aged_16.jpg\" width=\"80%\">\n",
    "\n",
    "> [picture source](https://zh.wikipedia.org/wiki/File:Alan_Turing_Aged_16.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**1950: Alan Turing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Enigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Universal calculation machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Does machine think?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Turing test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**1956 年達特矛斯第一屆 AI 會議**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4 school of aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| \\ | <h1><strong>human-like</strong></h1> | <h1><strong>rational</strong></h1> |\n",
    "| --- | --- | --- |\n",
    "| <h1><strong>thinking</strong></h1> | <h1>Thinking humanly</h1> | <h1>Thinking rationally</h1> |\n",
    "| <h1><strong>acting</strong></h1> | <h1>Acting humanly</h1> | <h1>Acting rationally</h1> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Acting humanly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/Turing_Robot.jpg\" width=\"80%\">\n",
    "\n",
    "> [picture source](http://humashah.blogspot.com/2016/10/what-is-turing-test.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thinking humanly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/Cognitive_Science.svg\" width=\"60%\">\n",
    "\n",
    "> [picture source](https://www.wikiwand.com/en/Cognitive_science)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thinking rationally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/rules-for-all.gif\" width=\"50%\">\n",
    "\n",
    "> [picture source](http://blog.chamasoft.com/successful-chama-needs-rules/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Acting rationally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/MP32.jpg\" width=\"30%\">\n",
    "\n",
    "> [picture source](https://www.federalmachine.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modern AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make smart **products or services**, rather than an **intelligent agent**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What does machine learning look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Methodology to solve problem.\n",
    "* Utilize math and probability.\n",
    "* Borrow the interpretation from science (e.g. physics)\n",
    "* Use the optimization approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where are ML in my life?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spam mail\n",
    "* Auto-fillin / autocomplete\n",
    "* Industry pipeline\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Relationship to other fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data mining\n",
    "* Data science\n",
    "* AI\n",
    "* Math\n",
    "* Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 會用模型\n",
    "2. 會調模型參數\n",
    "3. 理解模型的設計理念\n",
    "4. 可以讀懂 loss function 並理解每個運算的含義\n",
    "5. 會評估資料並且挑選適用的模型\n",
    "6. 可以自行修改模型\n",
    "7. 可以根據問題自行設計 loss function（將現實問題轉化為數學模型）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Types of learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduce several types of learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Supervised learning\n",
    "    * Training model with labels\n",
    "* Unsupervised learning\n",
    "    * Training model with labels\n",
    "* Semi-supervised learning\n",
    "    * Training model with partial labels\n",
    "* Reinforced learning\n",
    "    * Online learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| \\ | <h1><strong>continuous label</strong></h1> | <h1><strong>discrete label</strong></h1> |\n",
    "| --- | --- | --- |\n",
    "| <h1><strong>supervised</strong></h1> | <h1>Regression</h1> | <h1>Classification</h1> |\n",
    "| <h1><strong>unsupervised</strong></h1> | <h1>Density estimation</h1> | <h1>Clustering</h1> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/multiclass_classification.png\" width=\"80%\">\n",
    "\n",
    "> [picture source](https://www.ritchieng.com/logistic-regression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/clustering.gif\" width=\"80%\">\n",
    "\n",
    "> [picture source](https://home.deib.polimi.it/matteucc/Clustering/tutorial_html/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Density estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/Bivariate_example.png\" width=\"70%\">\n",
    "\n",
    "> [picture source](https://commons.wikimedia.org/wiki/File:Bivariate_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The simple example - linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\LARGE Y = mX + b\n",
    "$$\n",
    "\n",
    "<img src=\"pics/Linear_regression.svg\" width=\"80%\">\n",
    "\n",
    "> [picture source](https://zh.wikipedia.org/zh-tw/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Find the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**The best fit?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/find-the-model.png\" width=\"70%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Error measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/least_squares.gif\" width=\"60%\">\n",
    "\n",
    "> [picture source](https://www.quora.com/What-is-the-meaning-of-root-mean-squared-error-RMSE-in-statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean square error:\n",
    "\n",
    "$$\n",
    "\\large E(\\mathbf{\\hat{y}}, \\mathbf{y}) = \\frac{1}{N} \\sum_{i=1}^{N} (\\hat{y_i} - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\large = \\frac{1}{N} (\\mathbf{\\hat{y}} - \\mathbf{y})^T(\\mathbf{\\hat{y}} - \\mathbf{y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large \\mathcal{l}(\\mathbf{\\hat{y}}, \\mathbf{y}) = \\frac{1}{N} \\sum_{i=1}^{N} (\\hat{y_i} - y_i)^2 = \\frac{1}{N} \\sum_{i=1}^{N} (mx_i + b - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/gradient-descent.jpg\"  width=\"60%\">\n",
    "\n",
    "[picture source](http://www.sciencemag.org/news/2018/05/ai-researchers-allege-machine-learning-alchemy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contour of loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/Gradient_descent.svg\" width=\"50%\">\n",
    "\n",
    "> [picture source](https://en.wikipedia.org/wiki/File:Gradient_descent.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient descent algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_1 \\leftarrow$ random()\n",
    "\n",
    "while not converge\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$w_{t+1} \\leftarrow w_t - \\eta \\nabla l(x, y)$\n",
    "\n",
    "end\n",
    "\n",
    "* $w_t$: the weights/parameters of the model\n",
    "* $\\eta$: learning rate\n",
    "* $\\nabla l(x, y)$: gradient of the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Components of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model\n",
    "    * Linear model\n",
    "* Loss function and formulation\n",
    "    * Least square method\n",
    "* Optimization algorithm\n",
    "    * Gradient descent method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hypothesis set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到底有多少種可能的模型？\n",
    "\n",
    "$y = w_1 x + w_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$w_1 \\in \\mathbb{R}, w_0 \\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\mathcal{H} = \\{(w_0, w_1) \\mid w_1 \\in \\mathbb{R}, w_0 \\in \\mathbb{R}\\} = \\mathbb{R}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "有多少種可能的模型 $\\Rightarrow$ 搜尋空間 $\\Rightarrow$ Hypothesis set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要怎麼找到最適合資料的模型？\n",
    "\n",
    "Gradient descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Optimization problem: to find the best fit model (把問題轉成搜尋問題)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Issue:\n",
    "\n",
    "* local optima v.s. global optima\n",
    "* saddle point\n",
    "* multi-objective\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Optimization method:\n",
    "\n",
    "* Gradient-based methods\n",
    "    * Gradient descent method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Stochastic methods\n",
    "    * Heuristic methods\n",
    "        * Evolutionary algorithms\n",
    "        * ...\n",
    "    * Sampling methods\n",
    "        * Markov chain Monte Carlo\n",
    "        * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Infinite-dimensional optimization\n",
    "    * Calculus of variations\n",
    "    * Partial differential equations\n",
    "    * ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Framework of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/ml.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression (optimization aspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用 loss function 以及最佳化的數學方法找到極值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large arg\\,min_{a,b}\\ \\sum_i (ax_i + b - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\large \\mathcal{L}(a, b) = \\sum_i (ax_i + b - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\large arg\\,min_{a,b}\\ \\mathcal{L}(a, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Landscape of loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large \\mathcal{L}(a, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/paraboloid.png\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Partial) derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要求a, b分別是多少的時候，$\\mathcal{L}(a, b)$有最小值？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "微積分告訴我們，極值存在的地方，他的一階微分是 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "也就是\n",
    "\n",
    "$$\\large \\frac{\\partial \\mathcal{L}(a, b)}{\\partial a} = 0, \\frac{\\partial \\mathcal{L}(a, b)}{\\partial b} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Partial derivative respect to $a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\mathcal{L}(a, b) = \\sum_i (ax_i + b - y_i)^2, \\frac{\\partial \\mathcal{L}(a, b)}{\\partial a}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$= \\frac{\\partial}{\\partial a} \\sum_i (ax_i + b - y_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$= 2 \\sum_i x_i \\times (ax_i + b - y_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$= 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Partial derivative respect to $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\mathcal{L}(a, b) = \\sum_i (ax_i + b - y_i)^2, \\frac{\\partial \\mathcal{L}(a, b)}{\\partial b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$= \\frac{\\partial}{\\partial b} \\sum_i (ax_i + b - y_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$= 2 \\sum_i 1 \\times (ax_i + b - y_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$= 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large\n",
    "\\begin{cases}\n",
    "\\sum_i x_i \\times (ax_i + b - y_i) = 0 \\\\\n",
    "\\sum_i (ax_i + b - y_i) = 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\large\n",
    "\\begin{cases}\n",
    "(\\sum_i x_i^2) a + (\\sum_i x_i) b - (\\sum_i x_i y_i) = 0 \\\\\n",
    "(\\sum_i x_i) a + n b - (\\sum_i x_i y_i) = 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\large\n",
    "\\begin{cases}\n",
    "a = ? \\\\\n",
    "b = ?\n",
    "\\end{cases} \\\\\n",
    "(closed\\ form)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probability Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Complexity of the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們如何觀察這個複雜的世界？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/all_i_see_are_equations_1.png\" width=\"70%\">\n",
    "\n",
    "> [picture source](https://abstrusegoose.com/275)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Complexity of the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "科學家眼中的世界"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/all_i_see_are_equations_2.png\" width=\"70%\">\n",
    "\n",
    "> [picture source](https://abstrusegoose.com/275)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Complexity of the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "觀察可以獲得經驗，或是將經驗化成客觀的資料。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/stochastic.png\" width=\"70%\">\n",
    "\n",
    "> [picture source](https://thefinancialanalyst.net/2018/05/03/do-financial-analysts-with-expertise-in-stochastic-calculus-have-an-advantage-over-analysts-with-expertise-in-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Complexity of the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即便蒐集到資料，有時候也很難從中觀察出規律。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/chaos.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 你會怎麼描述資料？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "怎麼透過資料去得知真實世界的狀況？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/iris.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to say the pH value of pure water is 7.0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們從這個世界蒐集到的資料都不那麼完美\n",
    "\n",
    "> eg. 純水的 pH值是7.0，但 pH meter測出來都不會是準確的7.0，一定含有小數點"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "處理資料都會遇到不確定性（uncertainty）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "也就是，在大多數情況下\n",
    "\n",
    "> 純水的 pH值是接近7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "但是怎麼知道是7.0，而不是7.001，或是其他數字？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 事件 Event, $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 例如\n",
    "\n",
    "* 擲出正面：$\\{1\\}$\n",
    "* 擲出反面：$\\{0\\}$\n",
    "* 擲骰子點數為 1：$\\{1\\}$\n",
    "* 擲骰子點數為偶數：$\\{2, 4, 6\\}$\n",
    "* 擲骰子點數介於 2 到 4 之間：$\\{2, 3, 4\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 事件是元素（element）或是觀察到的結果（outcome）的集合\n",
    "\n",
    "#### 基本事件 elementary event：$\\{1\\}, \\{2\\}, \\{3\\}, \\{4\\}, \\{5\\}, \\{6\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Quiz\n",
    "\n",
    "$\\{\\}$ 是否為一個事件？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 樣本空間 Sample space, $\\Omega$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 所有可能\n",
    "\n",
    "* 擲骰子的所有可能：$\\{1, 2, 3, 4, 5, 6\\}$\n",
    "* 擲硬幣的所有可能：$\\{0, 1\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 定義\n",
    "\n",
    "* 樣本空間為所有可能的元素的集合。\n",
    "* 事件為樣本空間的子集合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 問題\n",
    "\n",
    "* 擲出兩個一樣的骰子的所有可能？\n",
    "* 擲出兩個一樣的骰子點數和的所有可能？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 機率 Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 基數 Cardinality\n",
    "\n",
    "$A = \\{1, 2, 3\\}$, $|A| = 3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### （古典、拉普拉斯）機率\n",
    "\n",
    "$$\n",
    "P(x) = \\frac{|x|}{|\\Omega|} = \\frac{\\text{事件中可能發生的結果}}{\\text{所有可能發生的結果}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 統計量 Statistics - 如何代表資料的集中趨勢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 集中趨勢\n",
    "\n",
    "* 平均值 mean\n",
    "* 中位數 median\n",
    "* 眾數 mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/normal.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 統計量 Statistics - 如何代表資料的離散趨勢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 離散趨勢\n",
    "\n",
    "* 標準差 standard deviation\n",
    "* 四分位距 interquartile range, IQR\n",
    "* 全距 range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/normal.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 公理化機率 Axioms of Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Axiom 1:\n",
    "\n",
    "$$0 \\le P(x) \\le 1, \\forall x \\subset \\Omega$$\n",
    "\n",
    "#### Axiom 2:\n",
    "\n",
    "$$P(\\Omega) = 1$$\n",
    "\n",
    "#### Axiom 3:\n",
    "\n",
    "$$P(\\bigcup_{i=1}^\\infty x_i) = \\sum_{i=1}^\\infty P(x_i)$$\n",
    "\n",
    "$x_i$ 為兩兩互斥事件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立在數學測度論（Measure Theory）之上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 隨機變數 Random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用來代表含有不確定性的變項"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 例子\n",
    "\n",
    "* $x = \\{1\\}$\n",
    "    * $P(X = 1)$\n",
    "* $x = \\{1, 2, 3\\}$\n",
    "    * $P(1 \\le X \\le 3)$\n",
    "* $x = ?$\n",
    "    * $P(X = x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 定義\n",
    "\n",
    "隨機變數其實是一個函數，$X: \\Omega \\rightarrow \\mathbb{R}$，會將事件中的結果對應到實數上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 機率分佈 Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果我們擲硬幣...\n",
    "\n",
    "$$\\Omega = \\{0, 1\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 擲一次，正面的機率\n",
    "\n",
    "$$\n",
    "x = \\{1\\} \\\\\n",
    "P(X=x) = \\frac{|x|}{|\\Omega|} = \\frac{1}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 擲三次，至少出現兩次正面的機率\n",
    "\n",
    "$$\n",
    "x = \\{(0, 1, 1), (1, 0, 1), (1, 1, 0), (1, 1, 1)\\} \\\\\n",
    "P(X=x) = \\frac{|x|}{|\\Omega|} = \\frac{4}{2^3} = \\frac{1}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 離散型分佈 Discrete distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 擲 n 次，出現 k 次正面\n",
    "\n",
    "$$\n",
    "P(X = k) = \\frac{C_n^k}{2^n} = C_n^k \\frac{1^k}{2^k} \\frac{1^{n-k}}{2^{n-k}} = C_n^k \\frac{1}{2}^k \\frac{1}{2}^{n-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 二項分佈 Binomial distribution\n",
    "\n",
    "$$\n",
    "P(X = k; n, p) = C_n^k p^k (1-p)^{n-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "　　　　　　　　１\n",
    "        \n",
    "　　　　　　　１　１\n",
    "       \n",
    "　　　　　　１　２　１\n",
    "      \n",
    "　　　　　１　３　３　１\n",
    "     \n",
    "　　　　１　４　６　４　１\n",
    "    \n",
    "　　　１　５　10　10　５　１"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 離散型分佈 Discrete distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 二項分佈 Binomial distribution\n",
    "\n",
    "$$\n",
    "P(X = k; n, p) = C_n^k p^k (1-p)^{n-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/Binomial_distribution_pmf.svg\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 伯努利分布 Bernoulli distribution\n",
    "\n",
    "$$\n",
    "P(X = x; p) = p^x (1-p)^{1-x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 均勻分佈 Uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/DUniform_distribution_PDF.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 卜瓦松分佈 Poisson distribution\n",
    "\n",
    "$$\n",
    "P(X=k; \\lambda) = \\frac{e^{- \\lambda} \\lambda^k}{k!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/Poisson_pmf.svg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 其他常見的離散型分佈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 幾何分布 Geometric distribution\n",
    "* 超幾何分佈\n",
    "* 負二項分佈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 連續型分佈 Continuous distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 常態分佈 Normal distribution\n",
    "\n",
    "$$\n",
    "P(X=x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} exp(- \\frac{(x - \\mu)^2}{2 \\sigma^2})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/Normal_Distribution_PDF.svg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 經驗法則"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/Empirical_Rule.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 指數分布 Exponential distribution\n",
    "\n",
    "$$\n",
    "P(X=x; \\lambda) = \\lambda e^{- \\lambda x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/Exponential_distribution_pdf.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 其他常見的連續型分佈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 對數常態分布\n",
    "* 拉普拉斯分布 Laplace distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 聯合機率分佈 Joint distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(X=x, Y=y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/Multivariate_normal_sample.svg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 邊際分布 Marginal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(X=x) = \\int P(X=x, Y=y) dy \\\\\n",
    "P(Y=y) = \\int P(X=x, Y=y) dx\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "P(X=x) = \\sum_{i=1}^{\\infty} P(X=x, Y=y_i) \\\\\n",
    "P(Y=y) = \\sum_{i=1}^{\\infty} P(X=x_i, Y=y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 估計 Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 在不確定性的世界不要奢望確定性，那不存在\n",
    "\n",
    "只存在大多數情況及例外"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Statistics is about inference and estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/inference_stats.svg\" height=\"400\" width=\"800\" alt=\"statistical inference\" style=\"background-color:white;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 假設"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 我們的樣本都是從同一個母體來的\n",
    "2. 樣本之間是互相獨立的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 統計量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們計算統計量：\n",
    "\n",
    "* $\\bar{x}$\n",
    "* $s$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "希望可以推估母體（機率模型）的參數\n",
    "\n",
    "* $\\mu$\n",
    "* $\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 期望值運算子 Expectation operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large P(X = x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\Large \\mathbb{E}[X] = \\sum_{i=1}^{n} x_i \\times P(X = x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\Large \\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x_i \\times P(X = x_i) dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 估計 Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 中央極限定理 Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/central_limit_thm_1.svg\" height=\"400\" style=\"background-color:white;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 中央極限定理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/central_limit_thm_2.svg\" height=\"500\" style=\"background-color:white;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 抽樣分佈 Sampling distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/sampling_dist.svg\" height=\"500\" style=\"background-color:white;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 抽樣分佈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/central_limit_thm_3.svg\" height=\"500\" style=\"background-color:white;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 中央極限定理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random samples $X_1, X_2, ..., X_n$\n",
    "\n",
    "from population with mean $\\mu$,\n",
    "\n",
    "if $n \\rightarrow \\infty$\n",
    "\n",
    "then $\\large \\mathbb{E}[X] \\rightarrow \\mu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Point estimation\n",
    "* Interval estimation\n",
    "\n",
    "<img src=\"pics/Standard_deviation_diagram.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 點估計 Point estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們由資料中得出資料的統計量：\n",
    "\n",
    "$\\LARGE \\bar{x} = \\frac{\\sum_{i=1}^{n} X_i}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "接著，我們用這個統計量推估（inference）母體的平均值：\n",
    "\n",
    "$\\LARGE \\mathbb{E}[\\bar{x}] = \\mu$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*$\\bar{x}$ is an unbiased estimation of $\\mu$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 點估計 Point estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們由資料中得出資料的統計量：\n",
    "\n",
    "$\\Large s^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "接著，我們用這個統計量推估（inference）母體的變異數：\n",
    "\n",
    "$\\Large \\mathbb{E}[s^2] = \\frac{(n - 1) \\times \\sigma^2}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*$s^2$ is an biased estimation of $\\sigma^2$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 點估計 Point estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "他提供給我們一個值，讓我們知道資料的集中跟離散的程度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "但是這個值有多精準呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "我們說這組資料的 $\\bar{x}$ 會往3.4集中，但..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "{3.4001, 3.3935, 3.4012, 3.3899, 3.4153}\n",
    "\n",
    "{7.033, 2.341, 3.753, 3.097, 1.908, 2.268}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 區間估計 Interval estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們利用區間來給出一個估計值\n",
    "\n",
    "<img src=\"pics/Standard_deviation_diagram.png\" style=\"background-color:white;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 區間估計 Interval estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常會用$[\\bar{x} - 1.96s, \\bar{x} + 1.96s]$區間（信賴區間）\n",
    "\n",
    "這個區間涵蓋了約95%的機會（信心水準）\n",
    "\n",
    "<img src=\"pics/Standard_deviation_diagram.png\" height=\"300\" style=\"background-color:white;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 區間估計 Interval estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 我有95%的信心 $\\mu$ 會落在$[\\bar{x} - 1.96s, \\bar{x} + 1.96s]$ 中\n",
    "\n",
    "<img src=\"pics/Standard_deviation_diagram.png\" style=\"background-color:white;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 區間估計 Interval estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 我有95%的信心 $\\mu$ 會落在[3.256, 3.544] 中\n",
    "\n",
    "<img src=\"pics/Standard_deviation_diagram.png\" style=\"background-color:white;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From distribution to model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 以平均值作為預測值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/random_walk.svg\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussian error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/stats-linear_reg1.svg\" width=\"80%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constant variance (homoscedasticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/stats-linear_reg2.svg\" width=\"70%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/multivariate.png\" width=\"70%\">\n",
    "\n",
    "$$\\large Y = a_0 + a_1X_1 + a_2X_2 + ... + a_nX_n$$\n",
    "\n",
    "> [picture source](https://stackoverflow.com/questions/26431800/plot-linear-model-in-3d-with-matplotlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear binary classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們希望建立一個分類器（classifier），可以幫我們把不同的資料分開："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Binary\n",
    "* Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/preceptron1.svg\" width=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear binary classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/preceptron2.svg\" width=\"40%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear separability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/linear_separable.png\" width=\"80%\">\n",
    "\n",
    "> [picture source](http://www.statistics4u.com/fundstat_eng/cc_classif_calib.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/preceptron3.svg\" width=\"40%\">\n",
    "\n",
    "$$\n",
    "sign(x) = \\begin{cases}\n",
    "-1, &\\text{if } x \\lt 0\\\\\n",
    "0, &\\text{if } x = 0\\\\\n",
    "1, &\\text{if } x \\gt 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Error function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mean square error\n",
    "* 0-1 loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 0-1 loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large \\mathcal{l}(y, \\hat{y}) = \\mathbb{I}(y \\cdot \\hat{y})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{I}(x) =\n",
    "\\begin{cases}\n",
    "0, &\\text{if}\\ x \\ge 0 \\\\\n",
    "1, &\\text{if}\\ x \\lt 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perceptron Learning Algorithm (PLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/pla.png\" width=\"50%\">\n",
    "\n",
    "> [picture source](http://cpmarkchang.logdown.com/posts/189108-machine-learning-perceptron-algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perceptron Learning Algorithm (PLA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{w_1} \\leftarrow$ random()\n",
    "\n",
    "while not all classify correctly\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if mistakes happens\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\mathbf{w_{t+1}} \\leftarrow \\mathbf{w_t} + \\mathbf{y}^T\\mathbf{x}$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One-versus-one (ovo)\n",
    "* One-versus-all (ova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/One-versus-all+classifier.jpg\" width=\"50%\">\n",
    "\n",
    "> [picture source](https://slideplayer.com/slide/7872916/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to evaluate the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/confusion_matrix.svg\" width=\"60%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large accuracy = \\frac{TP + TN}{\\text{total samples}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Type I and type II error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/type-i-and-type-ii-errors.jpg\" width=\"80%\">\n",
    "\n",
    "> [picture source](https://effectsizefaq.com/2010/05/31/i-always-get-confused-about-type-i-and-ii-errors-can-you-show-me-something-to-help-me-remember-the-difference/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hypothesis test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/R0ncP.png\" width=\"80%\">\n",
    "\n",
    "> [picture source](https://stats.stackexchange.com/questions/307568/type-i-error-in-research-what-is-the-alpha-of-a-study-especially-when-there-are)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contingency table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/contingency_table.svg\" width=\"60%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sensitivity and specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/Sensitivity_and_specificity2.svg\" width=\"80%\">\n",
    "\n",
    "> [picture source](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large f1 = \\frac{1}{\\frac{\\frac{1}{\\text{recall}} + \\frac{1}{\\text{precision}}}{2}} = \\frac{2}{\\frac{1}{\\text{recall}} + \\frac{1}{\\text{precision}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\large = \\frac{2 \\text{recall} \\times \\text{precision}}{\\text{recall} + \\text{precision}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Receiver operating characteristic (ROC) curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/roc1.png\" width=\"60%\">\n",
    "\n",
    "> [picture source](https://zh.wikipedia.org/wiki/ROC%E6%9B%B2%E7%BA%BF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Area under curve (AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/roc2.png\" width=\"80%\">\n",
    "\n",
    "> [picture source](https://zh.wikipedia.org/wiki/ROC%E6%9B%B2%E7%BA%BF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/logistic_reg.svg\" width=\"40%\">\n",
    "\n",
    "$$\n",
    "sigmoid(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/sigmoid.svg\" width=\"80%\">\n",
    "\n",
    "> [picture source](https://en.wikipedia.org/wiki/Sigmoid_function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
